# text =  Наше выработанное решение – обучить нейронную сеть, которая способна по тексту обращения автоматически распознавать заранее ранжированные по классам проблемы, извлекать сущность (номер заказа и телефон клиента) и по определённым классам сделать автоматизацию решения.
# relations = "Method_solves_Task 0 0, Method_solves_Task 0 1"
Наше O
выработанное O
решение O
– O
обучить O
нейронную B-Method_ML
сеть I-Method_ML
, O
которая O
способна B-Method_solves_Task
по O
тексту O
обращения O
автоматически B-Task
распознавать I-Task
заранее I-Task
ранжированные I-Task
по I-Task
классам I-Task
проблемы I-Task
, O
извлекать B-Task
сущность I-Task
( O
номер O
заказа O
и O
телефон O
клиента O
) O
и O
по O
определённым O
классам O
сделать O
автоматизацию O
решения O
. O

# text =   На самом деле уже существуют продвинутые и проверенные методы ее обработки, использующие нейронные сети, с распознаванием смысла и контекста – BERT (Bidirectional Encoder Representations from Transformers).
# relations = "Method_solves_Task 0 0, Model_isUsedForSolving_Task 0 0"
На O
самом O
деле O
уже O
существуют O
продвинутые O
и O
проверенные O
методы O
ее O
обработки O
, O
использующие O
нейронные B-Method_ML
сети I-Method_ML
, O
с O
распознаванием B-Task
смысла I-Task
и I-Task
контекста I-Task
– O
BERT B-Model
( O
Bidirectional B-Model
Encoder I-Model
Representations I-Model
from I-Model
Transformers I-Model
) O
. O

# text =   Перед тем как выбрать нейронные сети, мы протестировали несколько более стандартных архитектур, случайные леса и бустинг.
# relations = ""
Перед O
тем O
как O
выбрать O
нейронные B-Method_ML
сети I-Method_ML
, O
мы O
протестировали O
несколько O
более O
стандартных O
архитектур O
, O
случайные B-Method_ML
леса I-Method_ML
и O
бустинг B-Method_ML
. O

# text =   Эта модель была обучена на огромном корпусе русскоязычного текста с двумя задачами – предсказать замаскированное слово в предложениях и предсказать, если одно из предложений следует по смыслу за вторым.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isTrainedOn_Dataset 0 0"
Эта O
модель B-Model
была O
обучена B-Model_isTrainedOn_Dataset
на I-Model_isTrainedOn_Dataset
огромном O
корпусе B-Corpus
русскоязычного I-Corpus
текста I-Corpus
с O
двумя O
задачами O
– O
предсказать B-Task
замаскированное I-Task
слово I-Task
в I-Task
предложениях I-Task
и O
предсказать O
, O
если O
одно O
из O
предложений O
следует O
по O
смыслу O
за O
вторым O
. O

# text =   На обширном корпусе русскоязычного текста данная модель была обучена выполнять две задачи: предсказывать замаскированные слова в предложениях и определять, следует ли одно предложение за другим по смыслу.
# relations = "Model_isUsedForSolving_Task 0 0, Model_isTrainedOn_Dataset 0 0"
На O
обширном O
корпусе B-Corpus
русскоязычного I-Corpus
текста I-Corpus
данная O
модель B-Model
была O
обучена B-Model_isTrainedOn_Dataset
выполнять O
две O
задачи O
: O
предсказывать B-Task
замаскированные I-Task
слова I-Task
в I-Task
предложениях I-Task
и O
определять O
, O
следует O
ли O
одно O
предложение O
за O
другим O
по O
смыслу O
. O

# text =   Наша задача – дообучить эту языковую модель для нашего приложения (одна модель для классификации и одна – для извлечения сущности).
# relations = "Model_isUsedForSolving_Task 0 0, Model_isUsedForSolving_Task 0 1"
Наша O
задача O
– O
дообучить O
эту O
языковую O
модель O
для O
нашего O
приложения O
( O
одна O
модель B-Model
для B-Model_isUsedForSolving_Task
классификации B-Task
и O
одна O
– O
для B-Model_isUsedForSolving_Task
извлечения B-Task
сущности I-Task
) O
. O

# text =   результат первой модели – точность 77%
# relations = "Metric_hasValue_Value 0 0"
результат O
первой O
модели O
– O
точность B-Metric
77% B-Value

# text =   Чтобы определить, какие ещё есть потенциальные классы, мы повели так называемое тематическое моделирование, используя несколько подходов: начиная от пробалистических моделей (латентное распределение Дирихле, ARTM) и всё те же нейронные сети (BERT).
# relations = "Method_IsAlternativeNameFor_Method 2 1"
Чтобы O
определить O
, O
какие O
ещё O
есть O
потенциальные O
классы O
, O
мы O
повели O
так O
называемое O
тематическое B-Method
моделирование I-Method
, O
используя O
несколько O
подходов O
: O
начиная O
от O
пробалистических B-Model
моделей I-Model
( O
латентное B-Method_ML
распределение I-Method_ML
Дирихле I-Method_ML
, O
ARTM B-Method_ML
) O
и O
всё O
те O
же O
нейронные B-Method_ML
сети I-Method_ML
( O
BERT B-Model
) O
. O

# text =   Теперь нам нужно было использовать некоторые технические способы, чтобы сделать максимально высоким качество модели, которая на новых классах давала точность 72%.
# relations = "Metric_hasValue_Value 0 0, Metric_isUsedFor_Model 0 0"
Теперь O
нам O
нужно O
было O
использовать O
некоторые O
технические B-Method
способы I-Method
, O
чтобы O
сделать O
максимально O
высоким O
качество O
модели B-Model
, O
которая O
на O
новых O
классах O
давала O
точность B-Metric
72 B-Value
% I-Value
. O

# text =   Второе, мы стандартно провели экстенсивный тюнинг гиперпараметров и изменили нашу метрику с точности на F1, чтобы ставить больше акцента на точность по каждому классу, так как общая точность предвзято относится к доминирующим классам.
# relations = "Metric_isAppliedTo_Method 0 0, Metric_isAppliedTo_Method 1 0"
Второе O
, O
мы O
стандартно O
провели O
экстенсивный B-Method_ML
тюнинг I-Method_ML
гиперпараметров I-Method_ML
и O
изменили O
нашу O
метрику O
с O
точности B-Metric
на O
F1 B-Metric
, O
чтобы O
ставить O
больше O
акцента O
на O
точность B-Metric
по O
каждому O
классу O
, O
так O
как O
общая O
точность B-Metric
предвзято O
относится O
к O
доминирующим O
классам O
. O

# text =   Мы провели экстенсивный тюнинг гиперпараметров и переключили нашу метрику с точности на F1.
# relations = "Metric_isAppliedTo_Method 0 0, Metric_isAppliedTo_Method 1 0"
Мы O
провели O
экстенсивный B-Method_ML
тюнинг I-Method_ML
гиперпараметров I-Method_ML
и O
переключили O
нашу O
метрику O
с O
точности B-Metric
на O
F1 B-Metric
. O

# text =   Изменение оптимизирующей метрики на F1 позволило алгоритму обучения дольше обучаться, так как почти на каждом этапе происходило улучшение по F1, когда метрика была точность, мы достигали плато гораздо быстрее.
# relations = ""
Изменение O
оптимизирующей O
метрики O
на O
F1 B-Metric
позволило O
алгоритму O
обучения O
дольше O
обучаться O
, O
так O
как O
почти O
на O
каждом O
этапе O
происходило O
улучшение O
по O
F1 B-Metric
, O
когда O
метрика O
была O
точность B-Metric
, O
мы O
достигали O
плато O
гораздо O
быстрее O
. O

# text =   Изначально на этапе MVP (minimum viable product) мы применяли регулярные выражения для извлечения сущности.
# relations = "Method_is_applied_to_Object 0 0, Method_solves_Task 0 0"
Изначально O
на O
этапе O
MVP B-Object
( O
minimum B-Object
viable I-Object
product I-Object
) O
мы O
применяли B-Method_is_applied_to_Object
регулярные B-Method
выражения I-Method
для B-Method_solves_Task
извлечения B-Task
сущности I-Task
. O

# text =   Протестировав поведение модели на продовских данных, мы обнаружили, что точность извлечения была около 50%.
# relations = "Metric_hasValue_Value 0 0"
Протестировав O
поведение O
модели B-Model
на O
продовских O
данных O
, O
мы O
обнаружили O
, O
что O
точность B-Metric
извлечения O
была O
около O
50 B-Value
% I-Value
. O

# text =   Мы поняли, что даже извлечение сущности зависит от контекста, и решили использовать BERT.
# relations = "Model_isUsedForSolving_Task 0 0"
Мы O
поняли O
, O
что O
даже O
извлечение B-Task
сущности I-Task
зависит O
от O
контекста O
, O
и O
решили O
использовать B-Model_isUsedForSolving_Task
BERT B-Model
. O

# text =   На вход необходимо представить размеченные данные с маркировкой BIO (beginning, intermediate, O – пустота).
# relations = ""
На O
вход O
необходимо O
представить O
размеченные O
данные O
с O
маркировкой B-Object
BIO B-Object
( O
beginning O
, O
intermediate O
, O
O O
– O
пустота O
) O
. O

# text =   Мы производили разметку 800 обращений на DataTurcks: Точность подхода BERT – 94% на этапе обучения, она валидирована на тестовых данных.
# relations = "Metric_isAppliedTo_Method 0 1, Metric_hasValue_Value 0 0"
Мы O
производили O
разметку B-Method
800 O
обращений O
на O
DataTurcks B-Dataset
: O
Точность B-Metric
подхода B-Method_ML
BERT I-Method_ML
– O
94 B-Value
% I-Value
на O
этапе O
обучения O
, O
она O
валидирована O
на O
тестовых O
данных O
. O

# text =   Метод BERT демонстрирует точность 94% на этапе обучения, и эта точность проверена на тестовых данных.
# relations = "Metric_isAppliedTo_Method 0 1, Metric_hasValue_Value 0 0"
Метод B-Method_ML
BERT I-Method_ML
демонстрирует B-Metric_isAppliedTo_Method
точность B-Metric
94 B-Value
% I-Value
на O
этапе O
обучения O
, O
и O
эта O
точность B-Metric
проверена O
на O
тестовых O
данных O
. O

# text =   Это постобработка увеличила точность до 98%.
# relations = "Metric_hasValue_Value 0 0"
Это O
постобработка O
увеличила O
точность B-Metric
до O
98% B-Value

# text =   В иностранной литературе можно встретить термин Continuous Learning (CL), который объединяет различные методы использования новых данных для поддержания эффективности моделей.
# relations = "Method_includes_Method 0 2, Method_IsAlternativeNameFor_Method 1 0"
В O
иностранной O
литературе O
можно O
встретить O
термин O
Continuous B-Method
Learning I-Method
( O
CL B-Method
) O
, O
который O
объединяет B-Method_includes_Method
различные O
методы B-Method
использования I-Method
новых I-Method
данных I-Method
для I-Method
поддержания I-Method
эффективности I-Method
моделей I-Method
. O

# text =   Методы CL были положены в основу пайплайна переобучения.
# relations = ""
Методы O
CL B-Method
были O
положены O
в O
основу O
пайплайна O
переобучения O
. O
